{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import MultiIndex\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_test.hdf', 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value_features(values):\n",
    "    if type(values[0]) == np.float64:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[v.astype(float) for v in values]))\n",
    "    elif type(values[0]) == np.float:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "    if type(values[0]) == np.int64:\n",
    "        return tf.train.Feature(float_list=tf.train.Int64List(value=values))\n",
    "    elif type(values[0]) == str:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[v.encode() for v in values]))\n",
    "\n",
    "def value_feature(value):\n",
    "    if type(value) == np.float64:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value.astype(float)]))\n",
    "    elif type(value) == np.float:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "    elif type(value) == np.int64:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    elif type(value) == int:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    elif type(value) == str:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = pd.read_excel('Infos.xlsx').set_index(['id', 'study'])\n",
    "info.sex.fillna('NaN', inplace=True)\n",
    "info.self_size.fillna('NaN', inplace=True)\n",
    "info.shirt_size.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiple levels only valid with MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f67415e39b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.tfrecords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcur_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     feature = {'id': value_feature(_[0]), 'boardmac': value_feature(_[1]), \n\u001b[1;32m      5\u001b[0m                'study': value_feature(_[2]), 'period': value_feature(_[3])}\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   4414\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   4415\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4416\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   4417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[1;32m   2589\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No group keys passed!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m                     raise ValueError('multiple levels only valid with '\n\u001b[0m\u001b[1;32m   2592\u001b[0m                                      'MultiIndex')\n\u001b[1;32m   2593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiple levels only valid with MultiIndex"
     ]
    }
   ],
   "source": [
    "writer = tf.python_io.TFRecordWriter('train.tfrecords')\n",
    "for _, g in train.groupby(level=[0,1,2,3]):\n",
    "    cur_info = info.loc[_[0], _[2]]\n",
    "    feature = {'id': value_feature(_[0]), 'boardmac': value_feature(_[1]), \n",
    "               'study': value_feature(_[2]), 'period': value_feature(_[3])}\n",
    "    feature.update({column: value_feature(cur_info[column])\n",
    "               for column in ['sex', 'age', 'self_size', 'shirt_size', 'deodorant_left', 'deodorant_right']})\n",
    "    feature.update({'sequence_length': value_feature(g.shape[0])})\n",
    "    feature.update({column: value_features(g[column].values) for column in feature_columns})\n",
    "    feature.update({'timestamp': value_features([dt.timestamp() for dt in g['datetime'].dt.to_pydatetime()])})\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_columns = ['motion', 'temperature', \n",
    "              'sweat_10', 'sweat_11', 'sweat_12', 'sweat_13', 'sweat_14', 'sweat_15', 'sweat_16',\n",
    "              'sweat_r0', 'sweat_r1', 'sweat_r2', 'sweat_r3', 'sweat_r4', 'sweat_r5', 'sweat_r6']\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    features = {\n",
    "        'id': tf.FixedLenFeature((), tf.int64),\n",
    "        'boardmac': tf.FixedLenFeature((), tf.string),\n",
    "        'study': tf.FixedLenFeature((), tf.int64),\n",
    "        'period': tf.FixedLenFeature((), tf.int64),\n",
    "        'sex': tf.FixedLenFeature((), tf.string),\n",
    "        'age': tf.FixedLenFeature((), tf.float32),\n",
    "        'self_size': tf.FixedLenFeature((), tf.string),\n",
    "        'shirt_size': tf.FixedLenFeature((), tf.string),\n",
    "        'deodorant_left': tf.FixedLenFeature((), tf.int64),\n",
    "        'deodorant_right': tf.FixedLenFeature((), tf.int64),\n",
    "        'sequence_length': tf.FixedLenFeature((), tf.int64),\n",
    "        'timestamp': tf.FixedLenSequenceFeature((), tf.float32, allow_missing=True)\n",
    "    }\n",
    "    features.update({column: tf.FixedLenSequenceFeature((), tf.float32, allow_missing=True) for column in ts_columns})\n",
    "    return tf.parse_single_example(example_proto, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5cee40b7ffa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.tfrecords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m171\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.TFRecordDataset('train.tfrecords').map(_parse_function).shuffle(256)\n",
    "dataset = dataset.padded_batch(171, padded_shapes=dataset.output_shapes)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "example = iterator.get_next()\n",
    "\n",
    "rnn_cell = keras.layers.LSTMCell(units=14)\n",
    "rnn = keras.layers.RNN(rnn_cell, return_sequences=True)\n",
    "t = example['timestamp']\n",
    "t_diff = t[:,1:] - t[:, :-1]\n",
    "x = tf.stack([t_diff, example['motion'][:, 1:] / 960.0], 2)\n",
    "y_true = tf.stack([example[c][:, 1:] / 738600.0\n",
    "                   for c in [c for c in ts_columns if c.startswith('sweat')]], 2)\n",
    "y_pred = keras.layers.Dernn(x)\n",
    "loss = tf.reduce_mean(tf.reduce_mean(keras.losses.mean_squared_error(y_true, y_pred), 1), 0)\n",
    "\n",
    "opt = tf.train.AdamOptimizer()\n",
    "opt_op = opt.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c667ff5aec6b42048bf09c1525398346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "pb = tqdm_notebook(range(1000))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'model/model.ckpt')\n",
    "    \n",
    "    for epoch in pb:\n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                cur_loss, _ = sess.run([loss, opt_op])\n",
    "                pb.set_description(\"Current loss: %f\" % cur_loss)\n",
    "            except:\n",
    "                break\n",
    "        saver.save(sess, 'model/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
